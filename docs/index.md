# Home

<p align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/neuralmagic/guidellm/main/docs/assets/guidellm-logo-light.png">
    <img alt="GuideLLM Logo" src="https://raw.githubusercontent.com/neuralmagic/guidellm/main/docs/assets/guidellm-logo-dark.png" width=55%>
  </picture>
</p>

<h3 align="center">
Scale Efficiently: Evaluate and Optimize Your LLM Deployments for Real-World Inference
</h3>

**GuideLLM** is a platform for evaluating and optimizing the deployment of large language models (LLMs). By simulating real-world inference workloads, GuideLLM enables users to assess the performance, resource requirements, and cost implications of deploying LLMs on various hardware configurations. This approach ensures efficient, scalable, and cost-effective LLM inference serving while maintaining high service quality.

## Key Features

- **Performance Evaluation:** Analyze LLM inference under different load scenarios to ensure your system meets your service level objectives (SLOs).
- **Resource Optimization:** Determine the most suitable hardware configurations for running your models effectively.
- **Cost Estimation:** Understand the financial impact of different deployment strategies and make informed decisions to minimize costs.
- **Scalability Testing:** Simulate scaling to handle large numbers of concurrent users without performance degradation.

## Key Sections

<div class="grid cards" markdown>

- :material-rocket-launch:{ .lg .middle } Getting Started

    ---

    Install GuideLLM, set up your first benchmark, and analyze the results to optimize your LLM deployment.

    [:octicons-arrow-right-24: Getting started](./getting-started/)

- :material-book-open-variant:{ .lg .middle } Guides

    ---

    Detailed guides covering backends, datasets, metrics, and service level objectives for effective LLM benchmarking.

    [:octicons-arrow-right-24: Guides](./guides/)

- :material-code-tags:{ .lg .middle } Examples

    ---

    Step-by-step examples demonstrating real-world benchmarking scenarios and optimization techniques.

    [:octicons-arrow-right-24: Examples](./examples/)

- :material-api:{ .lg .middle } API Reference

    ---

    Complete reference documentation for the GuideLLM API to integrate benchmarking into your workflow.

    [:octicons-arrow-right-24: API Reference](./api/)

</div>
